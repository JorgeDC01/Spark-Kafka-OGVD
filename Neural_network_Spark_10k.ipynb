{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ea8dd9-3f0f-4c90-8683-db227e43bcfc",
   "metadata": {},
   "source": [
    "# **Apache Spark** 10k rows\n",
    "- Autores: Anny Álvarez Nogales, Paula Arias Fernández, Jorge del Castillo Gómez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a165406d-2b10-4507-90ac-22fa41acbe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/26 21:00:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local[*]\", \"Practica1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8da62e-911f-4801-8c0c-7cd37c5b755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filename):\n",
    "    text_file = sc.textFile(filename)\n",
    "    text_file = text_file.map(lambda linea: np.array(linea.split(',')).astype(float))\n",
    "    text_file= text_file.map(lambda x: (x[0:-1], int(x[-1])))\n",
    "    return text_file    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33531cd0-365e-405f-af6d-6b1da13dbdb0",
   "metadata": {},
   "source": [
    "CSV separado por comas \",\"\n",
    "\n",
    "num filas= 1.000.000, num columnas= 12\n",
    "\n",
    "Cada celda es un numero. \n",
    "\n",
    "La ultima celda de cada fila es la etiqueta (0/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f55b7-6a7a-4570-a9ee-c4328f27f885",
   "metadata": {},
   "source": [
    "FUNCIONES textFile, count, map, flatMap, reduce and reduceByKey. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f7e423-7dd2-40d3-9ce7-c663c38c8f0b",
   "metadata": {},
   "source": [
    "# **Ejercicio 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde680b7-f58e-4a39-955c-b43f066e477f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file= readFile('botnet_reduced_10k_l.csv')\n",
    "text_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b642061-2d1f-4248-b4ac-a700b2950ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize (RDD_Xy):\n",
    "    '''Normalize rdd'''\n",
    "    rdd_rows = RDD_Xy.map(lambda row: row[0])  \n",
    "    sumas = rdd_rows.reduce(lambda x, y: x + y)  \n",
    "    means_array = sumas / RDD_Xy.count()\n",
    "    \n",
    "    rdd_diff = rdd_rows.map(lambda x_array: (x_array - means_array)**2)\n",
    "    array_diff_sumatorio = rdd_diff.reduce(lambda x_row, y_row: x_row + y_row)\n",
    "    array_varianza = np.maximum(array_diff_sumatorio / RDD_Xy.count(), 0)\n",
    "\n",
    "    rdd_final = RDD_Xy.map(lambda row: (\n",
    "        np.array([(value - means_array[idx_column]) / np.sqrt(array_varianza[idx_column]) \n",
    "                  for idx_column, value in enumerate(row[0])]), row[1]\n",
    "    ) )\n",
    "    return rdd_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "588d859c-c606-4051-a95c-fb7d6686d509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([ 1.41281668, -0.75956071, -0.41204268, -0.45940748,  1.39580934,\n",
       "         -0.35386218,  0.74057161, -0.8945781 , -0.40163083, -2.91039199,\n",
       "          0.1567098 ]),\n",
       "  0),\n",
       " (array([-0.79867306, -0.89146231,  3.64034447, -0.45940748, -0.52296869,\n",
       "         -0.35387136,  0.55184122, -0.8945781 , -1.27444226,  0.4762026 ,\n",
       "          0.1567098 ]),\n",
       "  1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = normalize(text_file)\n",
    "data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d96336e-06bf-4186-980e-b01097f27574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm_test= data.map(lambda x : x[0])\n",
    "data_norm_test.stdev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a05bad9-ca3e-4689-b2db-f620a34ba045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [0]: [1.55015124]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [1]: [0.74621505]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [2]: [0.51013376]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [3]: [0.43356258]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [4]: [0.40450902]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [5]: [0.39189951]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [6]: [0.38591312]\n",
      "Iteration [7]: [0.38289613]\n",
      "Iteration [8]: [0.38130833]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [9]: [0.38044392]\n",
      "Accuracy:  0.9263\n"
     ]
    }
   ],
   "source": [
    "def compute_sigmoid(z):\n",
    "    y = (1 /(1 + np.exp(-z)))\n",
    "    return y  \n",
    "\n",
    "\n",
    "def predict(w, b, X):\n",
    "    y = compute_sigmoid(np.dot(X,w) + b)\n",
    "    if y >= 0.5:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "\n",
    "def accuracy(w,b, RDD_Xy):\n",
    "    y_hat = RDD_Xy.map(lambda x: (predict(w, b, x[0]), x[1]))  \n",
    "    preds = y_hat.map(lambda x: 1 if x[0] == x[1] else 0)\n",
    "    correct_preds = preds.reduce(lambda x, y: x + y)    \n",
    "    total = RDD_Xy.count()\n",
    "    accuracy = correct_preds / total\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train(RDD_Xy, iterations, learning_rate, lamba_reg):\n",
    "    # inicializar pesos\n",
    "    weights= np.random.rand(11)\n",
    "    biases = np.random.rand(1)   \n",
    "\n",
    "    for it in range(iterations):\n",
    "        # número de datos\n",
    "        m=RDD_Xy.count()\n",
    "        # calcular predicción (aplicar sigmoide a la multiplicación de los pesos más el sesgo)\n",
    "        rdd2=RDD_Xy.map(lambda x: (x[0], x[1],compute_sigmoid(np.dot(x[0],weights) + biases)))\n",
    "\n",
    "        item_2_costFunction = (lamba_reg/(2*11))*np.array([w**2 for w in weights]).sum() \n",
    "        \n",
    "        rdd2 = rdd2.map(lambda x: (x[0], x[1], x[2], -(x[1]*np.log(x[2]) + (1 - x[1])*np.log(1-x[2]))))\n",
    "        coste=rdd2.map(lambda x:x[3] )\n",
    "        coste=coste.reduce(lambda x,y:x+y )\n",
    "        \n",
    "        # gradientes\n",
    "        rdd3= rdd2.map(lambda x: ((x[2]-x[1])*x[0],(x[2]-x[1])))\n",
    "        rdd4= rdd3.reduce(lambda x,y: (x[0]+y[0], x[1]+y[1]))\n",
    "        weights2 = (weights * lamba_reg)/ len(weights)\n",
    "        d_weights= ((rdd4[0]/ m) + weights2 ) \n",
    "        d_bias= (rdd4[1]) / m\n",
    "        # actualización de las derivadas\n",
    "        weights = weights - learning_rate * d_weights\n",
    "        biases = biases - learning_rate * d_bias\n",
    "\n",
    "\n",
    "        coste=(coste/m) +  item_2_costFunction\n",
    "        print(f\"Iteration [{it}]: {coste}\")\n",
    "                \n",
    "    return weights, biases\n",
    "\n",
    "w, b, = train(data, 10, 1.5, 1)\n",
    "acc = accuracy(w, b, data)\n",
    "print (\"Accuracy: \", acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7611b01f-f8f6-4bc8-891d-63c0530980ce",
   "metadata": {},
   "source": [
    "# **Ejercicio 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ade36261-9b65-4b93-be6b-d1563dd13b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def transform(data, m, n_blocks):   \n",
    "    # calcular n de elementos de cada bloque\n",
    "    m_per_block = m // n_blocks\n",
    "\n",
    "    # creamos una lista de índices que representan las filas del conjunto de datos. Tiene valores del 0 al m-1 (m es el número total de filas)\n",
    "    indices = list(range(m)) \n",
    "    # mezclamos los índices para asegurarnos de que los datos se distribuyan de forma aleatoria entre los bloques\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    # la operación modulo % asegura que el índice de cada fila se asigna a un bloque específico.\n",
    "    # el resultado de 'indices.pop() % n_blocks' será un valor entre 0 y (n_blocks-1)\n",
    "    # el operador hace que los datos se distribuyan entre los bloques de manera UNIFORME\n",
    "    # los datos se asignen cíclicamente a bloques (0, 1, 2,... hasta n-1), y como esta desordenado ya se aplica el shuffle.\n",
    "\n",
    "    # ahora se tiene el resultado de la operacion modulo (y se añade como clave a cada fila)\n",
    "    indexed_data = data.map(lambda x: (indices.pop() % n_blocks, x)) \n",
    "    # 'x' es una fila del RDD original, y 'indices.pop() % n_blocks' le asigna un bloque aleatorio \n",
    "\n",
    "    return indexed_data.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32d7e5e7-df69-459a-a117-02aa9ff525de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block_data(data_cv, i, n_blocks):\n",
    "    #agrupamos los datos por bloque usando el valor de la clave (n de bloque) y almacenamos los datos al lado\n",
    "    #tengo (bloque/slice , dato (array y etiqueta))\n",
    "    grouped_data = data_cv.map(lambda x: (x[0], [x[1]])) \n",
    "\n",
    "    \n",
    "    #reduceByKey' para concatenar los elementos de la misma clave (bloque), es decir, agrupamos\n",
    "    #los datos que tienen el mismo valor de bloque.\n",
    "    grouped_data = grouped_data.reduceByKey(lambda a, b: a + b) \n",
    "    #aqui tenemos clave (n de bloque, lista de datos (filas con su array de 11 elementos, etiqueta))\n",
    "    \n",
    "    #en cada iteracion de este bucle trabajo con un slice o bloque \n",
    "    #tomamos todos los elementos cuyo bloque no sea el valor 'i' actual.\n",
    "    tr_data = grouped_data.map(lambda x: (x[0], [item for item in x[1] if x[0] != i]))\n",
    "    test_data = grouped_data.map(lambda x: (x[0], [item for item in x[1] if x[0] == i])) # el resto de test (elementos con clave el i)\n",
    "\n",
    "    # hasta ahora tenia lista de listas para cada bloque (al agrupar con reducebykey)\n",
    "    #aplano y tengo solo los datos no la clave del bloque (ya no se va a usar)\n",
    "    tr_data = tr_data.flatMap(lambda x: x[1])  \n",
    "    test_data = test_data.flatMap(lambda x: x[1])  \n",
    "    \n",
    "    return tr_data, test_data\n",
    "    return tr_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83af256a-021d-47f5-be8c-5b4e8f827caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Slice 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [0]: [1.13970598]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [1]: [0.65566578]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [2]: [0.45528112]\n",
      "Iteration [3]: [0.35905888]\n",
      "Iteration [4]: [0.30800585]\n",
      "Iteration [5]: [0.27786202]\n",
      "Iteration [6]: [0.25825711]\n",
      "Iteration [7]: [0.24453785]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [8]: [0.23440353]\n",
      "Iteration [9]: [0.22660613]\n",
      "acc : 0.9384615384615385\n",
      "\n",
      "Slice 2:\n",
      "Iteration [0]: [1.24227193]\n",
      "Iteration [1]: [0.61869779]\n",
      "Iteration [2]: [0.4150449]\n",
      "Iteration [3]: [0.33560295]\n",
      "Iteration [4]: [0.29493619]\n",
      "Iteration [5]: [0.27019277]\n",
      "Iteration [6]: [0.25344706]\n",
      "Iteration [7]: [0.24129997]\n",
      "Iteration [8]: [0.23205112]\n",
      "Iteration [9]: [0.22475285]\n",
      "acc : 0.9189723320158103\n",
      "\n",
      "Slice 3:\n",
      "Iteration [0]: [1.44634684]\n",
      "Iteration [1]: [0.7302127]\n",
      "Iteration [2]: [0.47138137]\n",
      "Iteration [3]: [0.36914633]\n",
      "Iteration [4]: [0.31752893]\n",
      "Iteration [5]: [0.28650018]\n",
      "Iteration [6]: [0.26574289]\n",
      "Iteration [7]: [0.25087205]\n",
      "Iteration [8]: [0.23969925]\n",
      "Iteration [9]: [0.23100293]\n",
      "acc : 0.9297872340425531\n",
      "\n",
      "Slice 4:\n",
      "Iteration [0]: [1.44295367]\n",
      "Iteration [1]: [0.69371113]\n",
      "Iteration [2]: [0.44479933]\n",
      "Iteration [3]: [0.35326426]\n",
      "Iteration [4]: [0.30702919]\n",
      "Iteration [5]: [0.27896584]\n",
      "Iteration [6]: [0.26004469]\n",
      "Iteration [7]: [0.24639726]\n",
      "Iteration [8]: [0.23607493]\n",
      "Iteration [9]: [0.22798562]\n",
      "acc : 0.9332669322709163\n",
      "\n",
      "Slice 5:\n",
      "Iteration [0]: [1.06168852]\n",
      "Iteration [1]: [0.59008646]\n",
      "Iteration [2]: [0.41016466]\n",
      "Iteration [3]: [0.33179723]\n",
      "Iteration [4]: [0.29076991]\n",
      "Iteration [5]: [0.26604483]\n",
      "Iteration [6]: [0.2496103]\n",
      "Iteration [7]: [0.23790625]\n",
      "Iteration [8]: [0.2291395]\n",
      "Iteration [9]: [0.22231678]\n",
      "acc : 0.9333333333333333\n",
      "\n",
      "Slice 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [0]: [1.27860027]\n",
      "Iteration [1]: [0.70275044]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [2]: [0.46568054]\n",
      "Iteration [3]: [0.3578965]\n",
      "Iteration [4]: [0.30294614]\n",
      "Iteration [5]: [0.2713919]\n",
      "Iteration [6]: [0.25132229]\n",
      "Iteration [7]: [0.23753501]\n",
      "Iteration [8]: [0.22750212]\n",
      "Iteration [9]: [0.2198729]\n",
      "acc : 0.9227799227799228\n",
      "\n",
      "Slice 7:\n",
      "Iteration [0]: [1.44701781]\n",
      "Iteration [1]: [0.72455781]\n",
      "Iteration [2]: [0.44506731]\n",
      "Iteration [3]: [0.34057846]\n",
      "Iteration [4]: [0.29131061]\n",
      "Iteration [5]: [0.2636122]\n",
      "Iteration [6]: [0.24606472]\n",
      "Iteration [7]: [0.2339916]\n",
      "Iteration [8]: [0.22517718]\n",
      "Iteration [9]: [0.21844968]\n",
      "acc : 0.926954732510288\n",
      "\n",
      "Slice 8:\n",
      "Iteration [0]: [1.08296151]\n",
      "Iteration [1]: [0.59426097]\n",
      "Iteration [2]: [0.40532188]\n",
      "Iteration [3]: [0.32359708]\n",
      "Iteration [4]: [0.28238287]\n",
      "Iteration [5]: [0.25833751]\n",
      "Iteration [6]: [0.24268693]\n",
      "Iteration [7]: [0.23167744]\n",
      "Iteration [8]: [0.22348443]\n",
      "Iteration [9]: [0.21712573]\n",
      "acc : 0.920997920997921\n",
      "\n",
      "Slice 9:\n",
      "Iteration [0]: [0.98099259]\n",
      "Iteration [1]: [0.57986182]\n",
      "Iteration [2]: [0.41886399]\n",
      "Iteration [3]: [0.34484669]\n",
      "Iteration [4]: [0.30360016]\n",
      "Iteration [5]: [0.27734526]\n",
      "Iteration [6]: [0.25916305]\n",
      "Iteration [7]: [0.24584166]\n",
      "Iteration [8]: [0.23567946]\n",
      "Iteration [9]: [0.22768563]\n",
      "acc : 0.9262452107279694\n",
      "\n",
      "Slice 10:\n",
      "Iteration [0]: [1.52438601]\n",
      "Iteration [1]: [0.82774328]\n",
      "Iteration [2]: [0.50575227]\n",
      "Iteration [3]: [0.37150799]\n",
      "Iteration [4]: [0.31047856]\n",
      "Iteration [5]: [0.27730354]\n",
      "Iteration [6]: [0.25657811]\n",
      "Iteration [7]: [0.24236957]\n",
      "Iteration [8]: [0.23199326]\n",
      "Iteration [9]: [0.22406611]\n",
      "acc : 0.9233009708737864\n",
      "average acc:  0.9274100128014039\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "path = 'botnet_reduced_10k_l.csv'\n",
    "data = readFile(path)\n",
    "\n",
    "# standardize\n",
    "data = normalize(data)\n",
    "\n",
    "num_blocks_cv = 10\n",
    "data_cv = transform(data, data.count(), num_blocks_cv)\n",
    "\n",
    "nIter = 10\n",
    "learningRate = 1.5\n",
    "lamba_reg = 0\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for i in range(num_blocks_cv):\n",
    "    tr_data, test_data = get_block_data(data_cv, i, num_blocks_cv)\n",
    "    \n",
    "    print(f\"\\nSlice {i+1}:\")\n",
    "    \n",
    "    w,b = train(tr_data, nIter, learningRate, lamba_reg)\n",
    "    acc = accuracy(w, b, test_data)\n",
    "    print(\"acc :\", acc)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "avg_acc = sum(accuracies) / num_blocks_cv\n",
    "print(\"average acc: \", avg_acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56710cd3-61cd-492b-a52e-0499c1a3e62b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
